import pandas as pd
import os
import logging
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from lightgbm import LGBMClassifier
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from app.titanic.titanic_method import TitanicMethod
from app.titanic.titanic_dataset import TitanicDataset

# Logger ì„¤ì •
logging.basicConfig(level=logging.INFO, format="%(message)s")
logger = logging.getLogger(__name__)

class TitanicService:
    """íƒ€ì´íƒ€ë‹‰ ìŠ¹ê° ë°ì´í„° ì²˜ë¦¬ ë° ë¨¸ì‹ ëŸ¬ë‹ ì„œë¹„ìŠ¤"""

    def __init__(self):
        self.dataset = None  # TitanicDataset ê°ì²´
        # ëª¨ë¸ë“¤
        self.lr_model = None
        self.nb_model = None
        self.rf_model = None
        self.lgbm_model = None
        self.svm_model = None
        # í•™ìŠµ/ê²€ì¦ ë°ì´í„°
        self.X_train = None
        self.X_val = None
        self.y_train = None
        self.y_val = None
        # í‰ê°€ ê²°ê³¼
        self.evaluation_results = None

    def preprocess(self):
        the_method = TitanicMethod()
        current_dir = os.path.dirname(os.path.abspath(__file__))

        # -----------------------------
        # ë°ì´í„° ì½ê¸°
        # -----------------------------
        train_path = os.path.join(current_dir, 'train.csv')
        test_path = os.path.join(current_dir, 'test.csv')
        df_train, df_test = the_method.read_csv(train_path, test_path)
        logger.info("â¤ï¸â¤ï¸ ë°ì´í„° ì½ê¸° ì™„ë£Œ")

        # -----------------------------
        # Train ì „ì²˜ë¦¬
        # -----------------------------
        this_train = the_method.create_df(df_train, 'Survived')       # featuresë§Œ
        this_label = the_method.create_label(df_train, 'Survived')    # label ìƒì„±

        logger.info("â¤ï¸â¤ï¸ Train ë°ì´í„° ì •ë³´")
        logger.info("1. Train ì˜ type: %s", type(this_train))
        logger.info("2. Train ì˜ columns: %s", list(this_train.columns))
        logger.info("3. Train ì˜ ìƒìœ„ 5ê°œ í–‰:\n%s", this_train.head(5))
        logger.info("4. Train null ê°œìˆ˜:\n%s", this_train.isnull().sum())

        # -----------------------------
        # Test ì „ì²˜ë¦¬
        # -----------------------------
        this_test = the_method.create_df(df_test, 'Survived')
        logger.info("ğŸ’›ğŸ’› Test ë°ì´í„° ì •ë³´")
        logger.info("1. Test ì˜ type: %s", type(this_test))
        logger.info("2. Test ì˜ columns: %s", list(this_test.columns))
        logger.info("3. Test ì˜ ìƒìœ„ 5ê°œ í–‰:\n%s", this_test.head(5))
        logger.info("4. Test null ê°œìˆ˜:\n%s", this_test.isnull().sum())

        # -----------------------------
        # TitanicDatasetìœ¼ë¡œ í†µí•©
        # -----------------------------
        this = TitanicDataset()
        this.train = this_train
        this.test = this_test
        this.label = this_label     # ì—¬ê¸°ì„œ label í• ë‹¹!

        self.dataset = this

        # -----------------------------
        # ì „ì²˜ë¦¬ ì ìš©
        # -----------------------------
        logger.info("â¤ï¸â¤ï¸ ì „ì²˜ë¦¬ ì‹œì‘")
        drop_features = ['SibSp', 'Parch', 'Ticket', 'Cabin']
        self.dataset = the_method.drop_features(self.dataset, *drop_features)
        self.dataset = the_method.pclass_ordinal(self.dataset)
        self.dataset = the_method.fare_ordinal(self.dataset)
        self.dataset = the_method.embarked_nominal(self.dataset)
        self.dataset = the_method.gender_nominal(self.dataset)
        self.dataset = the_method.title_nominal(self.dataset)  # Title ìƒì„± í›„ age_ratio
        self.dataset = the_method.age_ratio(self.dataset)

        # ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°
        drop_original = ['Name']
        self.dataset = the_method.drop_features(self.dataset, *drop_original)

        # -----------------------------
        # ì „ì²˜ë¦¬ í›„ ì •ë³´
        # -----------------------------
        logger.info("â¤ï¸â¤ï¸ ì „ì²˜ë¦¬ í›„ Train ë°ì´í„° ì •ë³´")
        logger.info("1. Train ì˜ type: %s", type(self.dataset.train))
        logger.info("2. Train ì˜ columns: %s", list(self.dataset.train.columns))
        logger.info("3. Train ì˜ ìƒìœ„ 5ê°œ í–‰:\n%s", self.dataset.train.head(5))
        logger.info("4. Train null ê°œìˆ˜:\n%s", self.dataset.train.isnull().sum())

        logger.info("ğŸ’›ğŸ’› ì „ì²˜ë¦¬ í›„ Test ë°ì´í„° ì •ë³´")
        logger.info("1. Test ì˜ type: %s", type(self.dataset.test))
        logger.info("2. Test ì˜ columns: %s", list(self.dataset.test.columns))
        logger.info("3. Test ì˜ ìƒìœ„ 5ê°œ í–‰:\n%s", self.dataset.test.head(5))
        logger.info("4. Test null ê°œìˆ˜:\n%s", self.dataset.test.isnull().sum())

        logger.info("â¤ï¸â¤ï¸ ì „ì²˜ë¦¬ ì™„ë£Œ!")

    # -----------------------------
    # ëª¨ë¸ë§, í•™ìŠµ, í‰ê°€
    # -----------------------------
    def modeling(self):
        """5ê°€ì§€ ì•Œê³ ë¦¬ì¦˜ ëª¨ë¸ ì´ˆê¸°í™”"""
        logger.info("â¤ï¸â¤ï¸ ëª¨ë¸ë§ ì‹œì‘")
        
        # 1. ë¡œì§€ìŠ¤í‹± íšŒê·€
        self.lr_model = LogisticRegression(max_iter=1000, random_state=42)
        
        # 2. ë‚˜ì´ë¸Œë² ì´ì¦ˆ
        self.nb_model = GaussianNB()
        
        # 3. ëœë¤í¬ë ˆìŠ¤íŠ¸
        self.rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
        
        # 4. LightGBM
        self.lgbm_model = LGBMClassifier(random_state=42, verbose=-1)
        
        # 5. SVM
        self.svm_model = SVC(kernel='rbf', random_state=42)
        
        logger.info("â¤ï¸â¤ï¸ ëª¨ë¸ë§ ì™„ë£Œ")

    def learning(self):
        """Train/Validation ë¶„í•  í›„ 5ê°€ì§€ ëª¨ë¸ í•™ìŠµ"""
        logger.info("â¤ï¸â¤ï¸ í•™ìŠµ ì‹œì‘")
        
        # ì „ì²˜ë¦¬ í›„ ê²°ì¸¡ì¹˜ í™•ì¸
        if self.dataset.train.isnull().sum().sum() > 0:
            raise ValueError("ì „ì²˜ë¦¬ í›„ì—ë„ ê²°ì¸¡ì¹˜ê°€ ë‚¨ì•„ìˆìŠµë‹ˆë‹¤.")
        
        # Train/Validation ë¶„í•  (80:20, stratify=y)
        X = self.dataset.train
        y = self.dataset.label.values.ravel()  # DataFrameì„ 1D arrayë¡œ ë³€í™˜
        
        self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        logger.info(f"Train ë°ì´í„°: {len(self.X_train)}ê°œ, Validation ë°ì´í„°: {len(self.X_val)}ê°œ")
        
        # 1. ë¡œì§€ìŠ¤í‹± íšŒê·€ í•™ìŠµ
        logger.info("ë¡œì§€ìŠ¤í‹± íšŒê·€ í•™ìŠµ ì¤‘...")
        self.lr_model.fit(self.X_train, self.y_train)
        
        # 2. ë‚˜ì´ë¸Œë² ì´ì¦ˆ í•™ìŠµ
        logger.info("ë‚˜ì´ë¸Œë² ì´ì¦ˆ í•™ìŠµ ì¤‘...")
        self.nb_model.fit(self.X_train, self.y_train)
        
        # 3. ëœë¤í¬ë ˆìŠ¤íŠ¸ í•™ìŠµ
        logger.info("ëœë¤í¬ë ˆìŠ¤íŠ¸ í•™ìŠµ ì¤‘...")
        self.rf_model.fit(self.X_train, self.y_train)
        
        # 4. LightGBM í•™ìŠµ
        logger.info("LightGBM í•™ìŠµ ì¤‘...")
        self.lgbm_model.fit(self.X_train, self.y_train)
        
        # 5. SVM í•™ìŠµ
        logger.info("SVM í•™ìŠµ ì¤‘...")
        self.svm_model.fit(self.X_train, self.y_train)
        
        logger.info("â¤ï¸â¤ï¸ í•™ìŠµ ì™„ë£Œ")

    def evaluate(self):
        """Validation ë°ì´í„°ë¡œ ê° ëª¨ë¸ í‰ê°€"""
        logger.info("â¤ï¸â¤ï¸ í‰ê°€ ì‹œì‘")
        
        # 1. ë¡œì§€ìŠ¤í‹± íšŒê·€ í‰ê°€
        lr_pred = self.lr_model.predict(self.X_val)
        lr_accuracy = accuracy_score(self.y_val, lr_pred)
        logger.info(f'ë¡œì§€ìŠ¤í‹± íšŒê·€ í™œìš©í•œ ê²€ì¦ ì •í™•ë„: {lr_accuracy:.4f}')
        
        # 2. ë‚˜ì´ë¸Œë² ì´ì¦ˆ í‰ê°€
        nb_pred = self.nb_model.predict(self.X_val)
        nb_accuracy = accuracy_score(self.y_val, nb_pred)
        logger.info(f'ë‚˜ì´ë¸Œë² ì´ì¦ˆ í™œìš©í•œ ê²€ì¦ ì •í™•ë„: {nb_accuracy:.4f}')
        
        # 3. ëœë¤í¬ë ˆìŠ¤íŠ¸ í‰ê°€
        rf_pred = self.rf_model.predict(self.X_val)
        rf_accuracy = accuracy_score(self.y_val, rf_pred)
        logger.info(f'ëœë¤í¬ë ˆìŠ¤íŠ¸ í™œìš©í•œ ê²€ì¦ ì •í™•ë„: {rf_accuracy:.4f}')
        
        # 4. LightGBM í‰ê°€
        lgbm_pred = self.lgbm_model.predict(self.X_val)
        lgbm_accuracy = accuracy_score(self.y_val, lgbm_pred)
        logger.info(f'LightGBM í™œìš©í•œ ê²€ì¦ ì •í™•ë„: {lgbm_accuracy:.4f}')
        
        # 5. SVM í‰ê°€
        svm_pred = self.svm_model.predict(self.X_val)
        svm_accuracy = accuracy_score(self.y_val, svm_pred)
        logger.info(f'SVM í™œìš©í•œ ê²€ì¦ ì •í™•ë„: {svm_accuracy:.4f}')
        
        # ê²°ê³¼ ì €ì¥
        self.evaluation_results = {
            "logistic_regression": float(lr_accuracy),
            "naive_bayes": float(nb_accuracy),
            "random_forest": float(rf_accuracy),
            "lightgbm": float(lgbm_accuracy),
            "svm": float(svm_accuracy)
        }
        
        logger.info("â¤ï¸â¤ï¸ í‰ê°€ ì™„ë£Œ")
        
        return self.evaluation_results
