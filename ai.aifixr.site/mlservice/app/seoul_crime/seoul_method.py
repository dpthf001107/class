import pandas as pd
from pandas import DataFrame
from app.seoul_crime.seoul_data import SeoulData   
import logging
import os
import matplotlib
matplotlib.use('Agg')  # GUI ë°±ì—”ë“œ ì—†ì´ ì‚¬ìš©
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler

# Logger ì„¤ì •
logging.basicConfig(level=logging.INFO, format="%(message)s")
logger = logging.getLogger(__name__)


class SeoulMethod(object):

    def __init__(self):
        pass

    # -----------------------------
    # ê¸°ë³¸ ì²˜ë¦¬
    # -----------------------------
    def csv_to_df(self, fname: str) -> pd.DataFrame:
        return pd.read_csv(fname)

    def xlsx_to_df(self, fname: str) -> pd.DataFrame:
        """
        Excel íŒŒì¼ì„ DataFrameìœ¼ë¡œ ì½ê¸°
        
        Args:
            fname: Excel íŒŒì¼ ê²½ë¡œ
        
        Returns:
            DataFrame
        """
        try:
            logger.info(f"ğŸ“– Excel íŒŒì¼ ì½ê¸°: {fname}")
            
            # .xls íŒŒì¼ì¸ ê²½ìš° xlrd ì‚¬ìš©
            if fname.endswith('.xls'):
                # MultiIndex ì»¬ëŸ¼ ì²˜ë¦¬ (header=[0,1]ë¡œ ì²« ë‘ í–‰ì„ í—¤ë”ë¡œ)
                df = pd.read_excel(fname, engine='xlrd', header=[0, 1])
            else:
                # .xlsx íŒŒì¼ì¸ ê²½ìš° openpyxl ì‚¬ìš©
                df = pd.read_excel(fname, engine='openpyxl')
            
            # MultiIndex ì»¬ëŸ¼ ì²˜ë¦¬
            if isinstance(df.columns, pd.MultiIndex):
                logger.info("  MultiIndex ì»¬ëŸ¼ ë³€í™˜ ì¤‘...")
                # ì²« ë²ˆì§¸ ë ˆë²¨ê³¼ ë‘ ë²ˆì§¸ ë ˆë²¨ì„ ê²°í•©
                new_columns = []
                for col in df.columns.values:
                    if isinstance(col, tuple) and len(col) == 2:
                        col0 = str(col[0]).strip() if pd.notna(col[0]) else ''
                        col1 = str(col[1]).strip() if pd.notna(col[1]) and str(col[1]) not in ['nan', ''] else ''
                        
                        if col1:
                            new_col = f"{col0}_{col1}"
                        else:
                            new_col = col0
                    else:
                        new_col = str(col[0]) if isinstance(col, tuple) else str(col)
                    
                    new_columns.append(new_col)
                
                df.columns = new_columns
                # ë¹ˆ ê°’ ì •ë¦¬
                df.columns = [col.replace('_nan', '').replace('nan_', '').replace('__', '_') 
                             for col in df.columns]
            
            logger.info(f"âœ… Excel ì½ê¸° ì™„ë£Œ: {len(df)}í–‰ Ã— {len(df.columns)}ì»¬ëŸ¼")
            logger.info(f"  ì»¬ëŸ¼ëª…: {', '.join(df.columns.tolist()[:15])}")  # ì²˜ìŒ 15ê°œë§Œ
            return df
            
        except Exception as e:
            logger.error(f"âŒ Excel ì½ê¸° ì˜¤ë¥˜: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            raise
    

    def df_merge(self, left_df: pd.DataFrame, right_df: pd.DataFrame, 
                 left_on: str, right_on: str, how: str = 'inner') -> pd.DataFrame:
        """
        ë‘ DataFrameì„ ë¨¸ì§€í•˜ê³  ì¤‘ë³µ ì»¬ëŸ¼ ì²˜ë¦¬
        
        Args:
            left_df: ì™¼ìª½ DataFrame
            right_df: ì˜¤ë¥¸ìª½ DataFrame
            left_on: ì™¼ìª½ í‚¤ ì»¬ëŸ¼ëª…
            right_on: ì˜¤ë¥¸ìª½ í‚¤ ì»¬ëŸ¼ëª…
            how: ë¨¸ì§€ ë°©ì‹ ('inner', 'left', 'right', 'outer')
        
        Returns:
            ë¨¸ì§€ëœ DataFrame
        """
        # ë¨¸ì§€ ì „ ì¤‘ë³µ ì»¬ëŸ¼ í™•ì¸
        common_cols = set(left_df.columns) & set(right_df.columns)
        common_cols.discard(left_on)
        common_cols.discard(right_on)
        
        if common_cols:
            logger.warning(f"âš ï¸ ì¤‘ë³µ ì»¬ëŸ¼ ë°œê²¬: {common_cols}")
        
        # ë¨¸ì§€ ìˆ˜í–‰
        logger.info(f"ğŸ“Š ë¨¸ì§€ ì‹œì‘: {left_on} â†” {right_on} (ë°©ì‹: {how})")
        df_merged = pd.merge(
            left_df, 
            right_df, 
            left_on=left_on, 
            right_on=right_on, 
            how=how,
            suffixes=('', '_drop')  # ì˜¤ë¥¸ìª½ì— _drop suffix
        )
        
        # ë¨¸ì§€ í›„ ì²˜ë¦¬
        if left_on != right_on:
            # ê°’ì´ ë™ì¼í•œì§€ í™•ì¸
            if (df_merged[left_on] == df_merged[right_on]).all():
                # left_onì„ right_onìœ¼ë¡œ renameí•˜ê³  right_on ì»¬ëŸ¼ ì œê±°
                df_merged = df_merged.drop(columns=[right_on])
                df_merged = df_merged.rename(columns={left_on: right_on})
                logger.info(f"âœ… '{left_on}' ì»¬ëŸ¼ì„ '{right_on}'ìœ¼ë¡œ ë³€ê²½ ('{left_on}'ê³¼ '{right_on}' ê°’ ë™ì¼)")
            else:
                logger.warning(f"âš ï¸ '{left_on}'ê³¼ '{right_on}' ê°’ì´ ë‹¤ë¦„. ë‘ ì»¬ëŸ¼ ëª¨ë‘ ìœ ì§€")
        
        # _drop suffix ì»¬ëŸ¼ ì œê±°
        drop_cols = [col for col in df_merged.columns if col.endswith('_drop')]
        if drop_cols:
            df_merged = df_merged.drop(columns=drop_cols)
            logger.info(f"ğŸ—‘ï¸ ì¤‘ë³µ ì»¬ëŸ¼ ì œê±°: {drop_cols}")
        
        logger.info(f"âœ¨ ë¨¸ì§€ ì™„ë£Œ: {len(df_merged)}ê°œ í–‰, {len(df_merged.columns)}ê°œ ì»¬ëŸ¼")
        return df_merged

    def geocode(self, address: str, lang: str = 'ko') -> tuple:
        # ì£¼ì†Œë¥¼ ìœ„ë„, ê²½ë„ë¡œ ë³€í™˜í•˜ëŠ” ë©”ì†Œë“œ
        pass

    def get_api_key(self) -> str:
        # api í‚¤ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë©”ì†Œë“œ
        pass

    def _clean_population_data(self, df_pop):
        """ì¸êµ¬ ë°ì´í„° ì •ë¦¬ ë©”ì„œë“œ"""
        logger.info("\nğŸ§¹ ì¸êµ¬ ë°ì´í„° ì»¬ëŸ¼ ë° í–‰ ì •ë¦¬")
        
        # 1. axis=1: ìì¹˜êµ¬ ì»¬ëŸ¼ê³¼ ì¢Œë¡œë¶€í„° 4ë²ˆì§¸ ì»¬ëŸ¼ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ ì‚­ì œ
        if 'ìì¹˜êµ¬' in df_pop.columns:
            # ìì¹˜êµ¬ ì»¬ëŸ¼ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
            ìì¹˜êµ¬_idx = df_pop.columns.get_loc('ìì¹˜êµ¬')
            # ì¢Œë¡œë¶€í„° 4ë²ˆì§¸ ì»¬ëŸ¼ (ì¸ë±ìŠ¤ 3)
            if len(df_pop.columns) > 3:
                cols_to_keep = [df_pop.columns[ìì¹˜êµ¬_idx], df_pop.columns[3]]
                df_pop = df_pop[cols_to_keep]
                logger.info(f"  ìœ ì§€ëœ ì»¬ëŸ¼: {cols_to_keep}")
            else:
                logger.warning("  ì»¬ëŸ¼ì´ 4ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤.")
        
        # 2. axis=0: ìœ„ë¡œë¶€í„° 2, 3, 4 ë²ˆì§¸ í–‰ ì œê±° (ì¸ë±ìŠ¤ 1, 2, 3)
        if len(df_pop) > 3:
            df_pop = df_pop.drop(df_pop.index[1:4])  # ì¸ë±ìŠ¤ 1, 2, 3 ì œê±°
            logger.info(f"  ì¸ë±ìŠ¤ 1, 2, 3 í–‰ ì œê±° ì™„ë£Œ")
        else:
            logger.warning("  í–‰ì´ 4ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤.")
        
        # 3. ì¸êµ¬ìˆ˜ ì»¬ëŸ¼ëª…ì„ 'ì¸êµ¬'ë¡œ ë³€ê²½ ë° ë°ì´í„° íƒ€ì… ë³€í™˜
        if len(df_pop.columns) >= 2:
            # ë‘ ë²ˆì§¸ ì»¬ëŸ¼ì´ ì¸êµ¬ìˆ˜ ì»¬ëŸ¼
            pop_col = df_pop.columns[1]
            df_pop = df_pop.rename(columns={pop_col: 'ì¸êµ¬'})
            
            # ìˆ«ìê°€ ì•„ë‹Œ í–‰ ì œê±° (ì˜ˆ: 'ê³„', 'í•©ê³„' ë“±)
            df_pop = df_pop[df_pop['ì¸êµ¬'].astype(str).str.replace(',', '').str.isdigit()]
            
            # ì¸êµ¬ìˆ˜ ë°ì´í„° íƒ€ì… ë³€í™˜ (ì‰¼í‘œ ì œê±°)
            df_pop['ì¸êµ¬'] = df_pop['ì¸êµ¬'].astype(str).str.replace(',', '').astype(float)
            logger.info(f"  ì¸êµ¬ ë°ì´í„° ì •ë¦¬ ì™„ë£Œ")
        
        return df_pop

    def generate_heatmap(self, crime_csv_path: str, pop_path: str, save_dir: str, 
                         df_pop_cleaned: pd.DataFrame = None,
                         crime_type: str = 'ë°œìƒ') -> dict:
        """
        ì„œìš¸ ë²”ì£„ ë°ì´í„° íˆíŠ¸ë§µ ìƒì„± (ì „ì²´ í”„ë¡œì„¸ìŠ¤ í¬í•¨)
        
        Args:
            crime_csv_path: ë²”ì£„ ë°ì´í„° CSV íŒŒì¼ ê²½ë¡œ
            pop_path: ì¸êµ¬ ë°ì´í„° Excel íŒŒì¼ ê²½ë¡œ
            save_dir: ì €ì¥ ê²½ë¡œ
            df_pop_cleaned: ì •ë¦¬ëœ ì¸êµ¬ ë°ì´í„° (ì„ íƒì‚¬í•­, ìˆìœ¼ë©´ ì¬ì‚¬ìš©)
            crime_type: ë²”ì£„ ìœ í˜• ('ë°œìƒ' ë˜ëŠ” 'ê²€ê±°'), ê¸°ë³¸ê°’: 'ë°œìƒ'
        
        Returns:
            ìƒì„±ëœ íˆíŠ¸ë§µ íŒŒì¼ ê²½ë¡œì™€ ë°ì´í„° ìš”ì•½ ì •ë³´ë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # crime_type ê²€ì¦
            if crime_type not in ['ë°œìƒ', 'ê²€ê±°']:
                raise ValueError(f"crime_typeì€ 'ë°œìƒ' ë˜ëŠ” 'ê²€ê±°'ì—¬ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬ ê°’: {crime_type}")
            
            # crime_typeì— ë”°ë¥¸ ì»¬ëŸ¼ëª… ì„¤ì •
            if crime_type == 'ê²€ê±°':
                numeric_cols = ['ì‚´ì¸ ê²€ê±°', 'ê°•ë„ ê²€ê±°', 'ê°•ê°„ ê²€ê±°', 'ì ˆë„ ê²€ê±°', 'í­ë ¥ ê²€ê±°']
                required_cols = ['ìì¹˜êµ¬', 'ì‚´ì¸ ê²€ê±°', 'ê°•ë„ ê²€ê±°', 'ê°•ê°„ ê²€ê±°', 'ì ˆë„ ê²€ê±°', 'í­ë ¥ ê²€ê±°']
                crime_cols = ['ì‚´ì¸ ê²€ê±°', 'ê°•ë„ ê²€ê±°', 'ê°•ê°„ ê²€ê±°', 'ì ˆë„ ê²€ê±°', 'í­ë ¥ ê²€ê±°']
                title_prefix = "ì„œìš¸ì‹œ ë²”ì£„ ê²€ê±°ë¥  ì •ê·œí™” íˆíŠ¸ë§µ (ì¸êµ¬ìˆ˜ ëŒ€ë¹„"
                cbar_label = 'ì •ê·œí™”ëœ ë²”ì£„ ê²€ê±°ë¥  (ì¸êµ¬ìˆ˜ ëŒ€ë¹„)'
                heatmap_filename = 'heatmap_arrest.png'
                log_prefix = "ê²€ê±°"
            else:  # crime_type == 'ë°œìƒ'
                numeric_cols = ['ì‚´ì¸ ë°œìƒ', 'ê°•ë„ ë°œìƒ', 'ê°•ê°„ ë°œìƒ', 'ì ˆë„ ë°œìƒ', 'í­ë ¥ ë°œìƒ']
                required_cols = ['ìì¹˜êµ¬', 'ì‚´ì¸ ë°œìƒ', 'ê°•ë„ ë°œìƒ', 'ê°•ê°„ ë°œìƒ', 'ì ˆë„ ë°œìƒ', 'í­ë ¥ ë°œìƒ']
                crime_cols = ['ì‚´ì¸ ë°œìƒ', 'ê°•ë„ ë°œìƒ', 'ê°•ê°„ ë°œìƒ', 'ì ˆë„ ë°œìƒ', 'í­ë ¥ ë°œìƒ']
                title_prefix = "ì„œìš¸ì‹œ ë²”ì£„ ë°œìƒë¥  ì •ê·œí™” íˆíŠ¸ë§µ (ì¸êµ¬ìˆ˜ ëŒ€ë¹„"
                cbar_label = 'ì •ê·œí™”ëœ ë²”ì£„ ë°œìƒë¥  (ì¸êµ¬ìˆ˜ ëŒ€ë¹„)'
                heatmap_filename = 'heatmap.png'
                log_prefix = "ë°œìƒ"
            
            # 1. CSV íŒŒì¼ ì½ê¸°
            logger.info(f"\nğŸ“‚ CSV íŒŒì¼ ì½ê¸°: {crime_csv_path}")
            
            if not os.path.exists(crime_csv_path):
                raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {crime_csv_path}")
            
            # CSV íŒŒì¼ ì½ê¸° (ì‰¼í‘œë¡œ êµ¬ë¶„)
            df = pd.read_csv(crime_csv_path, encoding='utf-8-sig')
            logger.info(f"  ì›ë³¸ ë°ì´í„° shape: {df.shape}")
            logger.info(f"  ì›ë³¸ ì»¬ëŸ¼: {df.columns.tolist()}")
            
            # ìˆ«ì ì»¬ëŸ¼ì—ì„œ ì‰¼í‘œ ì œê±° ë° ìˆ«ì ë³€í™˜
            for col in numeric_cols:
                if col in df.columns:
                    # ë¬¸ìì—´ì¸ ê²½ìš° ì‰¼í‘œ ì œê±° í›„ ìˆ«ì ë³€í™˜
                    df[col] = df[col].astype(str).str.replace(',', '').astype(float)
            
            logger.info(f"\nâœ… CSV íŒŒì¼ ì½ê¸° ì™„ë£Œ")
            logger.info(f"  ë°ì´í„° shape: {df.shape}")
            logger.info(f"  ìƒìœ„ 3ê°œ:\n{df.head(3).to_string()}")
            
            # 2. íˆíŠ¸ë§µ ìƒì„±ì— í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë‚¨ê¸°ê¸°
            logger.info(f"\nğŸ§¹ íˆíŠ¸ë§µ ìƒì„±ì— í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ ({log_prefix} ë°ì´í„°)")
            
            # í•„ìˆ˜ ì»¬ëŸ¼ì´ ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_cols}")
            
            df_selected = df[required_cols].copy()
            logger.info(f"  ì„ íƒëœ ì»¬ëŸ¼: {df_selected.columns.tolist()}")
            logger.info(f"  ë°ì´í„° shape: {df_selected.shape}")
            
            # 3. ë™ì¼ ìì¹˜êµ¬ì— ì—¬ëŸ¬ ê´€ì„œê°€ ìˆëŠ” ê²½ìš° ê±´ìˆ˜ í•©ì‚°
            logger.info(f"\nğŸ“Š ìì¹˜êµ¬ë³„ {log_prefix} ê±´ìˆ˜ í•©ì‚°")
            logger.info(f"  í•©ì‚° ì „ í–‰ ìˆ˜: {len(df_selected)}")
            logger.info(f"  ìì¹˜êµ¬ë³„ ê´€ì„œ ìˆ˜:\n{df_selected.groupby('ìì¹˜êµ¬').size()}")
            
            df_grouped = df_selected.groupby('ìì¹˜êµ¬')[crime_cols].sum()
            
            logger.info(f"  í•©ì‚° í›„ í–‰ ìˆ˜: {len(df_grouped)}")
            logger.info(f"  í•©ì‚° ê²°ê³¼ (ìƒìœ„ 5ê°œ):\n{df_grouped.head(5).to_string()}")
            
            # 4. ì¸êµ¬ ë°ì´í„° ë¡œë“œ ë° ë¨¸ì§€
            logger.info("\nğŸ“Š ì¸êµ¬ ë°ì´í„° ë¡œë“œ ë° ë¨¸ì§€")
            
            # ì´ë¯¸ ì •ë¦¬ëœ ì¸êµ¬ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ë¡œë“œ ë° ì •ë¦¬
            if df_pop_cleaned is not None:
                logger.info("  âœ… ì •ë¦¬ëœ ì¸êµ¬ ë°ì´í„° ì¬ì‚¬ìš©")
                df_pop = df_pop_cleaned.copy()
            else:
                logger.info("  ğŸ“‚ ì¸êµ¬ ë°ì´í„° ë¡œë“œ ë° ì •ë¦¬")
                df_pop = self.xlsx_to_df(pop_path)
                
                # ìì¹˜êµ¬ ì»¬ëŸ¼ í™•ì¸ ë° ë§¤í•‘
                if 'ìì¹˜êµ¬' not in df_pop.columns:
                    if 'ìì¹˜êµ¬_ìì¹˜êµ¬' in df_pop.columns:
                        df_pop = df_pop.rename(columns={'ìì¹˜êµ¬_ìì¹˜êµ¬': 'ìì¹˜êµ¬'})
                    else:
                        if len(df_pop.columns) > 0:
                            first_col = df_pop.columns[0]
                            if 'ê¸°ê°„' not in str(first_col) and 'í•©ê³„' not in str(first_col):
                                df_pop = df_pop.rename(columns={first_col: 'ìì¹˜êµ¬'})
                
                # ì¸êµ¬ ë°ì´í„° ì •ë¦¬
                df_pop = self._clean_population_data(df_pop)
            
            logger.info(f"  ì¸êµ¬ ë°ì´í„° shape: {df_pop.shape}")
            logger.info(f"  ì¸êµ¬ ë°ì´í„° (ìƒìœ„ 5ê°œ):\n{df_pop.head(5).to_string()}")
            
            # ë²”ì£„ ë°ì´í„°ì™€ ì¸êµ¬ ë°ì´í„° ë¨¸ì§€
            df_merged = df_grouped.reset_index().merge(df_pop, on='ìì¹˜êµ¬', how='inner')
            df_merged = df_merged.set_index('ìì¹˜êµ¬')
            logger.info(f"  ë¨¸ì§€ í›„ shape: {df_merged.shape}")
            logger.info(f"  ë¨¸ì§€ ê²°ê³¼ (ìƒìœ„ 3ê°œ):\n{df_merged.head(3).to_string()}")
            
            # 5. ì¸êµ¬ìˆ˜ ëŒ€ë¹„ ë¹„ìœ¨ ê³„ì‚° (ì¸êµ¬ 10ë§Œëª…ë‹¹)
            logger.info(f"\nğŸ“Š ì¸êµ¬ìˆ˜ ëŒ€ë¹„ {log_prefix}ë¥  ê³„ì‚° (ì¸êµ¬ 10ë§Œëª…ë‹¹)")
            df_rate = df_merged[crime_cols].div(df_merged['ì¸êµ¬'], axis=0) * 100000
            logger.info(f"  {log_prefix}ë¥  ê³„ì‚° ì™„ë£Œ")
            logger.info(f"  {log_prefix}ë¥  ê²°ê³¼ (ìƒìœ„ 3ê°œ):\n{df_rate.head(3).to_string()}")
            
            # 6. ì´ ë²”ì£„ ë¹„ìœ¨ ì»¬ëŸ¼ ì¶”ê°€ (í­ë ¥ ë‹¤ìŒì— ì¶”ê°€)
            logger.info(f"\nâ• ì´ ë²”ì£„ {log_prefix}ë¥  ì»¬ëŸ¼ ì¶”ê°€")
            df_rate['ë²”ì£„'] = df_rate.sum(axis=1)
            
            # ì»¬ëŸ¼ ìˆœì„œ ì¬ì •ë ¬: ì‚´ì¸, ê°•ë„, ê°•ê°„, ì ˆë„, í­ë ¥, ë²”ì£„ ìˆœì„œ
            if crime_type == 'ê²€ê±°':
                column_order = ['ì‚´ì¸ ê²€ê±°', 'ê°•ë„ ê²€ê±°', 'ê°•ê°„ ê²€ê±°', 'ì ˆë„ ê²€ê±°', 'í­ë ¥ ê²€ê±°', 'ë²”ì£„']
            else:
                column_order = ['ì‚´ì¸ ë°œìƒ', 'ê°•ë„ ë°œìƒ', 'ê°•ê°„ ë°œìƒ', 'ì ˆë„ ë°œìƒ', 'í­ë ¥ ë°œìƒ', 'ë²”ì£„']
            
            # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì¬ì •ë ¬
            existing_columns = [col for col in column_order if col in df_rate.columns]
            if len(existing_columns) != len(column_order):
                missing = set(column_order) - set(existing_columns)
                logger.warning(f"âš ï¸ ì¼ë¶€ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}")
            
            df_rate = df_rate[existing_columns]
            logger.info(f"  ì¶”ê°€ëœ ì»¬ëŸ¼: {df_rate.columns.tolist()}")
            logger.info(f"  ì´ ë²”ì£„ {log_prefix}ë¥  (ìƒìœ„ 5ê°œ):\n{df_rate[['ë²”ì£„']].head(5).to_string()}")
            
            # 7. ì •ê·œí™”(Normalization) ìˆ˜í–‰
            logger.info(f"\nğŸ“ MinMax ì •ê·œí™” ìˆ˜í–‰ ({log_prefix}ë¥  ê¸°ì¤€, 0~1 ì‚¬ì´ë¡œ ìŠ¤ì¼€ì¼ë§)")
            # ì»¬ëŸ¼ ìˆœì„œ ì €ì¥
            column_order_before_norm = df_rate.columns.tolist()
            
            scaler = MinMaxScaler()
            df_norm = pd.DataFrame(
                scaler.fit_transform(df_rate),
                columns=df_rate.columns,
                index=df_rate.index
            )
            
            # ì»¬ëŸ¼ ìˆœì„œê°€ ìœ ì§€ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if df_norm.columns.tolist() != column_order_before_norm:
                logger.warning(f"âš ï¸ ì •ê·œí™” í›„ ì»¬ëŸ¼ ìˆœì„œê°€ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤. ì¬ì •ë ¬í•©ë‹ˆë‹¤.")
                df_norm = df_norm[column_order_before_norm]
            
            logger.info(f"  ì •ê·œí™” ì™„ë£Œ")
            logger.info(f"  ì •ê·œí™” ê²°ê³¼ (ìƒìœ„ 3ê°œ):\n{df_norm.head(3).to_string()}")
            
            # 8. ì •ê·œí™”ëœ ë²”ì£„ ë¹„ìœ¨(ì´ ë²”ì£„) ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            logger.info(f"\nğŸ“Š ì •ê·œí™”ëœ ë²”ì£„ {log_prefix}ë¥ (ì´ ë²”ì£„) ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬")
            # ê²€ê±°ì¼ ë•ŒëŠ” ì •ê·œí™”ëœ ê²€ê±°ìœ¨ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            df_norm = df_norm.sort_values(by='ë²”ì£„', ascending=False)
            logger.info(f"  ì •ë ¬ ì™„ë£Œ")
            logger.info(f"  ì •ë ¬ ê²°ê³¼ (ìƒìœ„ 5ê°œ):\n{df_norm[['ë²”ì£„']].head(5).to_string()}")
            
            # 9. íˆíŠ¸ë§µ ìƒì„± (ë¹¨ê°„ìƒ‰ ê³„ì—´-í•˜ì–€ìƒ‰)
            logger.info("\nğŸ¨ íˆíŠ¸ë§µ ìƒì„± ì¤‘...")
            
            # ì €ì¥ ê²½ë¡œ ì„¤ì •
            os.makedirs(save_dir, exist_ok=True)
            
            heatmap_files = []
            
            # Xì¶• ë ˆì´ë¸” ìƒì„± (ë²”ì£„ ìœ í˜•ë§Œ í‘œì‹œ, 'ë°œìƒ' ë˜ëŠ” 'ê²€ê±°' ì œê±°)
            x_labels = []
            for col in df_norm.columns:
                if col == 'ë²”ì£„':
                    x_labels.append('ë²”ì£„')
                else:
                    # 'ì‚´ì¸ ë°œìƒ' -> 'ì‚´ì¸', 'ì‚´ì¸ ê²€ê±°' -> 'ì‚´ì¸'
                    label = col.replace(' ë°œìƒ', '').replace(' ê²€ê±°', '')
                    x_labels.append(label)
            
            # íˆíŠ¸ë§µ ìƒ‰ìƒ ì„¤ì •: ê²€ê±°ëŠ” íŒŒë€ìƒ‰, ë°œìƒì€ ë¹¨ê°„ìƒ‰
            cmap_color = "Blues" if crime_type == 'ê²€ê±°' else "Reds"
            
            # íˆíŠ¸ë§µ ìƒì„±
            plt.figure(figsize=(14, 10))
            sns.heatmap(df_norm, annot=True, fmt=".6f", cmap=cmap_color, 
                       xticklabels=x_labels, yticklabels=True,
                       cbar_kws={'label': cbar_label})
            plt.title(f"{title_prefix})", fontsize=18, pad=20, fontweight='bold')
            plt.xlabel('ë²”ì£„ ìœ í˜•', fontsize=14, fontweight='bold')
            plt.ylabel('ìì¹˜êµ¬', fontsize=14, fontweight='bold')
            plt.xticks(rotation=45, ha='right', fontsize=11)
            plt.yticks(rotation=0, fontsize=11)
            plt.tight_layout()
            
            heatmap_path = os.path.join(save_dir, heatmap_filename)
            plt.savefig(heatmap_path, dpi=300, bbox_inches='tight', facecolor='white')
            plt.close()
            heatmap_files.append(heatmap_path)
            logger.info(f"  âœ… íˆíŠ¸ë§µ ì €ì¥: {heatmap_path}")
            
            logger.info("\nâœ… íˆíŠ¸ë§µ ìƒì„± ì™„ë£Œ!")
            
            # ë°˜í™˜ ë°ì´í„° êµ¬ì„±
            return {
                "status": "success",
                "message": "íˆíŠ¸ë§µ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤",
                "heatmap_files": heatmap_files,
                "data_summary": {
                    "total_districts": len(df_grouped),
                    "crime_types": df_grouped.columns.tolist(),
                    "normalized_data_preview": df_norm.head(5).to_dict(orient='index')
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ íˆíŠ¸ë§µ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            raise